---
title: Tuning the Beast
slug: tuning-the-beast
image: ./images/st-george_3.jpeg
date: 2020-07-10
author: brian griner
category: machine learning
readTime: 15
---

import { Link } from 'gatsby'

## Review of LSTM Tuning Methods for Forecasting Time Series

Long Short-Term Memory networks (LSTMs) are a special type of Recurrent Neural Network (RNN) specifically designed to capture long-term
correlations in a sequence without producing the technical issues of vanishing or exploding gradients during
training associated with RNNs. Other benefits of LSTMs for sequence prediction are:

1.  Internal memory state that can learn the temporal structure of the inputs
2.  Ability to learn multiple parallel input sequences separately
3.  Does't require a fixed window for input/output sequences like a multilayer perceptron (MLP)

**What is an LSTM?** An LSTM network consists of sequential **Memory Blocks** composed of three sets of weights and gates:

**Weights**

1. Input weights
2. Output weights
3. Internal State (Cell state)

**Gates**

1. Forget gate
2. Input gate
3. Output gate

```python
%matplotlib inline
import warnings
warnings.filterwarnings('ignore')

# load and plot dataset
from pandas import read_csv
from pandas import datetime
from matplotlib import pyplot
# load dataset
datafile = '~/NOTEBOOKS-LSTM-timeseries/data/Month-shampooSales.csv'
def parser(x):
    return datetime.strptime('190'+x, '%Y-%m')
series = read_csv(datafile, header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)
# summarize first few rows
print(series.head())
# line plot
series.plot()
pyplot.show()
Month
1901-01-01    266.0
1901-02-01    145.9
1901-03-01    183.1
1901-04-01    119.3
1901-05-01    180.3
Name: shampooSales, dtype: float64
```

<Link to="/posts" className="btn center-btn">
  all posts
</Link>
